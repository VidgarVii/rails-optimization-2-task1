# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: Количество итераций в секунду. 

При чтении и парсинга файла data.txt Выходные данные из benchmark-ips

`2.995k (± 1.5%) i/s` 

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. 
Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.
Для упрощение кода и выделение абстракций я вынес тестирование программы в отдельную директорию `spec`
Тестирование будет заниматься библиотека `rspec`
## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: 

* Тестирование
* Создание профайла. Поиск точек старта
* Оптимизация кода

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался библиотеками

- rbspy
- benchmark
- ruby-prof

Вот какие проблемы удалось найти и решить

### Ваша находка №1
Вынес тест отдельно из программы. Чтобы не мазолил глаза. Не место тестам в теле основной программы.
Добавил возможность менять подключаемый файл с данными и отключение GC. Через аттрибуты метода work.
Для поиска точки роста использовал профилировщики:
* rbspy - не дал результатов. Основная нагрузка была в самом block in work. Метод work грамозкий и является антипатерном GodObject. 
Для получения более подробной информации метод надо разбить на простые методы. 
* ruby-prof - Указал на высокую нагрузку CPU при чтении и записи данных. А так же при парсинге даты.
* benchmarks/ips (file: data.txt)
`2.995k (± 1.5%) i/s`

Бросается на глаза чтение всего файла, дробление по строчно и запись строк в массив. 
Так как при большом объеме данных забивается память. Решение использовать читать файл с данными по строчно.

* Использовал метод File#foreach. Чтобы не записывать все данные в память. А проводить все операции по строчно.
Обернул реализацию парсинга данных в блок #foreach

И всё пошло по бороде. Если начинать с точки старта, требуется для начало провести не хилый рефакт

Довел код до зеленных тестов. Пока получилось правда с запашком. 

Треды не включал. Всё происходит синхронно

#### Результаты benchmark на маленьком файле

* benchmarks/ips (file: data.txt)
`2.111k (± 3.4%) i/s -     10.441k in   5.035906s`

#### Результат ruby-prof на большом файле
```
Total: 52.027112 

14.89     39.910     7.745     0.000    32.166        1   <Class::IO>#foreach
10.85      8.168     5.642     0.000     2.525  2750940   User#update
7.90      4.108     4.108     0.000     0.000  3250940   String#split
7.76      8.193     4.037     0.000     4.157        1   JSON::Ext::Generator::GeneratorMethods::Hash#to_json
```


### Ваша находка №2
О вашей находке №2

### Ваша находка №X
О вашей находке №X

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
